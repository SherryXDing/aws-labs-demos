{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e6995f93",
   "metadata": {},
   "source": [
    "# Build and train a sample autoencoder model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e935987f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python Version:  3.6.13\n",
      "TensorFlow Version:  2.1.3\n"
     ]
    }
   ],
   "source": [
    "from platform import python_version\n",
    "\n",
    "print(\"Python Version: \",python_version())\n",
    "\n",
    "import tensorflow as tf\n",
    "print(\"TensorFlow Version: \",tf.version.VERSION)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc11b9a6",
   "metadata": {},
   "source": [
    "## Model definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "378e8ff2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_3 (InputLayer)         [(None, 5)]               0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 3)                 18        \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 3)                 12        \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 2)                 8         \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 3)                 9         \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 3)                 12        \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 5)                 20        \n",
      "=================================================================\n",
      "Total params: 79\n",
      "Trainable params: 79\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import Model, Input\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.layers import Dropout, Dense\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, TensorBoard\n",
    "from tensorflow.keras import regularizers\n",
    "\n",
    "#[5,3,2,3,5]\n",
    "\n",
    "\n",
    "# Layer 1 input size\n",
    "input_dim = 5\n",
    "encoding_dim = 3\n",
    "\n",
    "#Activation Function\n",
    "afn=\"tanh\"\n",
    "\n",
    "input_layer = Input(shape=(input_dim, ))\n",
    "encoder = Dense(encoding_dim, activation=afn,activity_regularizer=regularizers.l1(10e-5))(input_layer)\n",
    "encoder = Dense(int(encoding_dim), activation=afn)(encoder)\n",
    "encoder = Dense(int(2), activation=afn)(encoder) # bottleneck\n",
    "decoder = Dense(int(encoding_dim), activation=afn)(encoder)\n",
    "decoder = Dense(int(encoding_dim), activation=afn)(decoder)\n",
    "decoder = Dense(input_dim, activation=afn)(decoder)\n",
    "autoencoder = Model(inputs=input_layer, outputs=decoder)\n",
    "autoencoder.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7b7ce8e",
   "metadata": {},
   "source": [
    "## Training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3bb35fae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 5)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "X_train_scaled = np.random.rand(100, 5)\n",
    "X_train_scaled.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d333459",
   "metadata": {},
   "source": [
    "## Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3f7ae6a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 90 samples, validate on 10 samples\n",
      "90/90 [==============================] - 1s 8ms/sample - loss: 0.3896 - val_loss: 0.3334\n",
      "Time to run the model: 0.739431 Sec.\n"
     ]
    }
   ],
   "source": [
    "import datetime\n",
    "\n",
    "nb_epoch = 1\n",
    "batch_size = 5\n",
    "autoencoder.compile(optimizer='adam', loss='mse' )\n",
    "\n",
    "t_ini = datetime.datetime.now()\n",
    "\n",
    "# X_train_scaled, X_train_scaled (Unsupervised Learning)\n",
    "\n",
    "history = autoencoder.fit(x=X_train_scaled, y=X_train_scaled,\n",
    "                        epochs=nb_epoch,\n",
    "                        batch_size=batch_size,\n",
    "                        shuffle=True,\n",
    "                        validation_split=0.1,\n",
    "                        verbose=1\n",
    "                        ).history\n",
    "\n",
    "t_fin = datetime.datetime.now()\n",
    "print('Time to run the model: {} Sec.'.format((t_fin - t_ini).total_seconds()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18209287",
   "metadata": {},
   "source": [
    "## Save model to SavedModel format which is compatible with Tensorflow Serving"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d385c4b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/ec2-user/anaconda3/envs/tensorflow2_p36/lib/python3.6/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1786: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n",
      "INFO:tensorflow:Assets written to: model_sherry/1/assets\n"
     ]
    }
   ],
   "source": [
    "!mkdir -p model_sherry\n",
    "autoencoder.save('model_sherry/1/', save_format='tf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "306e4fdf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "MetaGraphDef with tag-set: 'serve' contains the following SignatureDefs:\n",
      "\n",
      "signature_def['__saved_model_init_op']:\n",
      "  The given SavedModel SignatureDef contains the following input(s):\n",
      "  The given SavedModel SignatureDef contains the following output(s):\n",
      "    outputs['__saved_model_init_op'] tensor_info:\n",
      "        dtype: DT_INVALID\n",
      "        shape: unknown_rank\n",
      "        name: NoOp\n",
      "  Method name is: \n",
      "\n",
      "signature_def['serving_default']:\n",
      "  The given SavedModel SignatureDef contains the following input(s):\n",
      "    inputs['input_3'] tensor_info:\n",
      "        dtype: DT_FLOAT\n",
      "        shape: (-1, 5)\n",
      "        name: serving_default_input_3:0\n",
      "  The given SavedModel SignatureDef contains the following output(s):\n",
      "    outputs['dense_11'] tensor_info:\n",
      "        dtype: DT_FLOAT\n",
      "        shape: (-1, 5)\n",
      "        name: StatefulPartitionedCall:0\n",
      "  Method name is: tensorflow/serving/predict\n",
      "WARNING:tensorflow:From /home/ec2-user/anaconda3/envs/tensorflow2_p36/lib/python3.6/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1786: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n",
      "\n",
      "Defined Functions:\n",
      "  Function Name: '__call__'\n",
      "    Option #1\n",
      "      Callable with:\n",
      "        Argument #1\n",
      "          inputs: TensorSpec(shape=(None, 5), dtype=tf.float32, name='inputs')\n",
      "        Argument #2\n",
      "          DType: bool\n",
      "          Value: False\n",
      "        Argument #3\n",
      "          DType: NoneType\n",
      "          Value: None\n",
      "    Option #2\n",
      "      Callable with:\n",
      "        Argument #1\n",
      "          input_3: TensorSpec(shape=(None, 5), dtype=tf.float32, name='input_3')\n",
      "        Argument #2\n",
      "          DType: bool\n",
      "          Value: False\n",
      "        Argument #3\n",
      "          DType: NoneType\n",
      "          Value: None\n",
      "    Option #3\n",
      "      Callable with:\n",
      "        Argument #1\n",
      "          inputs: TensorSpec(shape=(None, 5), dtype=tf.float32, name='inputs')\n",
      "        Argument #2\n",
      "          DType: bool\n",
      "          Value: True\n",
      "        Argument #3\n",
      "          DType: NoneType\n",
      "          Value: None\n",
      "    Option #4\n",
      "      Callable with:\n",
      "        Argument #1\n",
      "          input_3: TensorSpec(shape=(None, 5), dtype=tf.float32, name='input_3')\n",
      "        Argument #2\n",
      "          DType: bool\n",
      "          Value: True\n",
      "        Argument #3\n",
      "          DType: NoneType\n",
      "          Value: None\n",
      "\n",
      "  Function Name: '_default_save_signature'\n",
      "    Option #1\n",
      "      Callable with:\n",
      "        Argument #1\n",
      "          input_3: TensorSpec(shape=(None, 5), dtype=tf.float32, name='input_3')\n",
      "\n",
      "  Function Name: 'call_and_return_all_conditional_losses'\n",
      "    Option #1\n",
      "      Callable with:\n",
      "        Argument #1\n",
      "          inputs: TensorSpec(shape=(None, 5), dtype=tf.float32, name='inputs')\n",
      "        Argument #2\n",
      "          DType: bool\n",
      "          Value: True\n",
      "        Argument #3\n",
      "          DType: NoneType\n",
      "          Value: None\n",
      "    Option #2\n",
      "      Callable with:\n",
      "        Argument #1\n",
      "          inputs: TensorSpec(shape=(None, 5), dtype=tf.float32, name='inputs')\n",
      "        Argument #2\n",
      "          DType: bool\n",
      "          Value: False\n",
      "        Argument #3\n",
      "          DType: NoneType\n",
      "          Value: None\n",
      "    Option #3\n",
      "      Callable with:\n",
      "        Argument #1\n",
      "          input_3: TensorSpec(shape=(None, 5), dtype=tf.float32, name='input_3')\n",
      "        Argument #2\n",
      "          DType: bool\n",
      "          Value: True\n",
      "        Argument #3\n",
      "          DType: NoneType\n",
      "          Value: None\n",
      "    Option #4\n",
      "      Callable with:\n",
      "        Argument #1\n",
      "          input_3: TensorSpec(shape=(None, 5), dtype=tf.float32, name='input_3')\n",
      "        Argument #2\n",
      "          DType: bool\n",
      "          Value: False\n",
      "        Argument #3\n",
      "          DType: NoneType\n",
      "          Value: None\n"
     ]
    }
   ],
   "source": [
    "!saved_model_cli show --all --dir 'model_sherry/1/'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1c56f85",
   "metadata": {},
   "source": [
    "## Create a model archive file (model.tar.gz) and upload to s3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "daee4c4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "!tar -C \"$PWD\" -czf model.tar.gz model_sherry/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "29d9f00c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model uploaded to: s3://sagemaker-us-east-2-240487350066/ised_demo_model/model.tar.gz\n"
     ]
    }
   ],
   "source": [
    "from sagemaker.session import Session\n",
    "\n",
    "model_data = Session().upload_data(path='model.tar.gz', key_prefix='ised_demo_model')\n",
    "print('model uploaded to: {}'.format(model_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f8478f6",
   "metadata": {},
   "source": [
    "## Wrap into a SageMaker TensorflowModel object and deploy to a real-time endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2c4e32db",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "update_endpoint is a no-op in sagemaker>=2.\n",
      "See: https://sagemaker.readthedocs.io/en/stable/v2.html for details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------!"
     ]
    }
   ],
   "source": [
    "from sagemaker.tensorflow import TensorFlowModel\n",
    "from sagemaker import get_execution_role\n",
    "# from sagemaker.deserializers import JSONDeserializer\n",
    "# from sagemaker.serializers import CSVSerializer\n",
    "\n",
    "sagemaker_role = get_execution_role()\n",
    "\n",
    "model = TensorFlowModel(model_data=model_data, role=sagemaker_role, framework_version='2.1.3')\n",
    "predictor = model.deploy(initial_instance_count=1, instance_type='ml.g4dn.xlarge')\n",
    "# predictor = model.deploy(initial_instance_count=1, instance_type='ml.g4dn.xlarge', serializer=CSVSerializer(), deserializer=JSONDeserializer())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7874f645",
   "metadata": {},
   "source": [
    "## Make predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9888a1ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 5)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.03436834, 0.05735075, 0.03385664, 0.23529412, 0.0223518 ]])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The gamma model expects an input of shape [1,5]\n",
    "gamma_input = np.array([[0.03436834, 0.05735075, 0.03385664, 0.23529412, 0.0223518 ]])\n",
    "\n",
    "#model_input = gamma_input.reshape(1, 5)\n",
    "\n",
    "print(gamma_input.shape)\n",
    "gamma_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1f5bd8f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'predictions': [[0.171888843,\n",
       "   0.0929558352,\n",
       "   0.100073166,\n",
       "   -0.0468236022,\n",
       "   -0.0452863686]]}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictor.predict(gamma_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f7e47ef3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# delete endpoint\n",
    "predictor.delete_endpoint()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f52ffed2",
   "metadata": {},
   "source": [
    "### When using a lambda function to invoke the endpoint, the code would be something like:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96520527",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import boto3\n",
    "\n",
    "# endpoint_name = predictor.endpoint_name\n",
    "# sagemaker_runtime = boto3.client('sagemaker-runtime')\n",
    "# response = sagemaker_runtime.invoke_endpoint(EndpointName = endpoint_name, \n",
    "#                                    ContentType = 'specify_content_type', \n",
    "#                                    Body = your_payload)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa357c76",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_tensorflow2_p36",
   "language": "python",
   "name": "conda_tensorflow2_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
